{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2679eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, TimeDistributed, Bidirectional, LSTM,\n",
    "    Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285adeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "VIOLENCE_PATH = \"data/Violence\"\n",
    "NONVIOLENCE_PATH = \"data/NonViolence\"\n",
    "SEQUENCE_LENGTH = 16\n",
    "IMG_HEIGHT = 224  # MobileNetV2 default input size\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3908f72",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    indices = np.linspace(0, total_frames - 1, SEQUENCE_LENGTH, dtype=int)\n",
    "\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            resized_frame = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            normalized_frame = resized_frame / 255.0\n",
    "            frames.append(normalized_frame)\n",
    "        else:\n",
    "            # In case of reading error, append a black frame\n",
    "            frames.append(np.zeros((IMG_HEIGHT, IMG_WIDTH, CHANNELS)))\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def load_dataset(violence_path, nonviolence_path):\n",
    "    sequences, labels = [], []\n",
    "    class_map = {\"Violence\": 1, \"NonViolence\": 0}\n",
    "\n",
    "    for class_name, label in class_map.items():\n",
    "        path = violence_path if class_name == \"Violence\" else nonviolence_path\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "\n",
    "        video_files = [f for f in os.listdir(path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        for video in tqdm(video_files, desc=f\"Loading {class_name}\"):\n",
    "            video_path = os.path.join(path, video)\n",
    "            frames = extract_frames(video_path)\n",
    "            if frames is not None and len(frames) == SEQUENCE_LENGTH:\n",
    "                sequences.append(frames)\n",
    "                labels.append(label)\n",
    "\n",
    "    if not sequences:\n",
    "        raise ValueError(\"No videos found. Please check dataset paths.\")\n",
    "\n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab1b47",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86367ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(sequence_length, img_height, img_width, channels):\n",
    "    input_shape = (sequence_length, img_height, img_width, channels)\n",
    "\n",
    "    # CNN Feature Extractor (MobileNetV2)\n",
    "    base_cnn = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(img_height, img_width, channels),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base_cnn.trainable = False\n",
    "\n",
    "    # Model Definition\n",
    "    model_input = Input(shape=input_shape)\n",
    "    cnn_features = TimeDistributed(base_cnn)(model_input)\n",
    "\n",
    "    # BiLSTM for Temporal Analysis\n",
    "    bilstm_out = Bidirectional(LSTM(128))(cnn_features)\n",
    "\n",
    "    # Dense Layers and Regularization\n",
    "    x = Dense(64, activation='relu')(bilstm_out)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Output Layer\n",
    "    model_output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=model_input, outputs=model_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab7304",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    target_names = [\"Non-Violence\", \"Violence\"]\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_history(history):\n",
    "    metrics = ['loss', 'accuracy', 'precision', 'recall', 'f1_score']\n",
    "    plt.figure(figsize=(14, 10))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(3, 2, i + 1)\n",
    "        plt.plot(history.history[metric], label=f'Train {metric.capitalize()}')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric.capitalize()}')\n",
    "        plt.title(f'{metric.capitalize()} Over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b4e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Violence: 100%|██████████| 1000/1000 [06:55<00:00,  2.40it/s]\n",
      "Loading Non-Violence: 100%|██████████| 1000/1000 [03:12<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6051 - loss: 0.6583 - precision: 0.6022 - recall: 0.7085"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare the dataset\n",
    "    X, y = load_dataset(VIOLENCE_PATH, NONVIOLENCE_PATH)\n",
    "    y_one_hot = to_categorical(y, num_classes=2)\n",
    "\n",
    "    # Split the data: 80% for training + validation and 20% for testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_one_hot, test_size=0.2, stratify=y_one_hot, random_state=42\n",
    "    )\n",
    "    # From the 80% training set, take 20% for validation (which is 16% of the full dataset)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    "    )\n",
    "\n",
    "    # Build the model\n",
    "    model = build_model(SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.F1Score(name='f1_score', average='macro')\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=metrics\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    # Plot training metrics\n",
    "    plot_training_history(history)\n",
    "\n",
    "    # Save the final model\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    model.save(\"results/violence_detection_model.h5\")\n",
    "    print(\"\\nModel saved to results/violence_detection_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05518e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
